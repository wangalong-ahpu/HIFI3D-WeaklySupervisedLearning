output_dir: "/root/autodl-tmp/demo/AlbedoGAN_TR/coarse/0531_resnet50_b8K1_68_4090"
#tensorboard --logdir /media/wang/SSD_2/demo/DECA_TR/pretrain/0307_convnextV2_8_235_1080/logs
pretrained_modelpath: '/root/autodl-tmp/demo/AlbedoGAN/data/deca_model.tar'
#pretrained_modelpath: '/media/wang/SSD_1/demo/DECA_TR/pretrain/4090_convnextV2_16_235_0108_none/model.tar'

#æ•°æ®é›†åœ°å€
facescape_dir: "/root/autodl-tmp/Datasets/fmview_train_new"
small_facescape_dir: "/root/autodl-tmp/Datasets/small_facescape_new"
vggface2_dir: "/root/autodl-tmp/Datasets/vggface2_new"
lymh_dir: "/root/autodl-tmp/Datasets/LYMH_new"


aflw2000_dir: "/root/autodl-tmp/Datasets/AFLW2000/image/2"

use_mica: False
train_other_params: False


dataset:
  training_data: [ 'facescape']
  eval_data: [ 'aflw2000' ]
  batch_size: 16
  K: 1
train:
  resume: False
  max_epochs: 11
  max_steps: 2000000
  log_steps: 500
  vis_steps: 500
  checkpoint_steps: 1000
  val_steps: 10000
model:
  #resnet50 convnext_v1  convnext_v2_tiny convnext_v2_atto
  E_flame_backbone: 'resnet50'
  # face_eye_mask_path: "/home/wang/wal/demo_test/DECA/data/uv_face_eye_mask_y.png"
  face_eye_mask_path: "/root/autodl-tmp/demo/AlbedoGAN/data/uv_face_eye_mask.png"
#  flame_lmk_embedding_path: "/home/wang/wal/demo_test/DECA/data/res.npy"
  n_shape: 100
  n_exp: 50
loss:
  # with ğœ†ğ‘â„ğ‘œ=2.0, ğœ†ğ‘–ğ‘‘=0.2, ğœ†ğ‘ ğ‘=1.0, ğœ†ğ‘™ğ‘šğ‘˜=1.0, ğœ†ğ‘’ğ‘¦ğ‘’=1.0, ğœ†ğœ·=1ğ‘’âˆ’4, and ğœ†ğ=1ğ‘’âˆ’4.
  photo: 1.0 #2.0

  lmk_num: 68
  lmk: 1.
  mouthkc: 0.0  # æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°æ–°
  eyed:  1.0  #1.0
  lipd: 0.3  #0.3

  id: 0.5 #0.5

  id_shape_only: True
  shape_consistency: True

  reg_shape: 1e-04
  reg_exp: 1e-04
  reg_tex: 1e-04
  reg_light: 1.
  reg_jaw_pose: 1. #1.

  useSeg: True

#python main_train.py --cfg configs/1080/coarse.yml
# '''
# detail:
# This is followed by training the detail model (i.e. ğ¸ğ‘‘
# and ğ¹ğ‘‘
# ) on VGGFace2 and VoxCeleb2 with a batch size of 6, with
# 3 images per subject, and parameters ğœ†ğ‘â„ğ‘œğ· = 2.0, ğœ†ğ‘šğ‘Ÿ ğ‘“ = 5ğ‘’ âˆ’ 2,
# ğœ†ğ‘ ğ‘¦ğ‘š = 5ğ‘’ âˆ’ 3, ğœ†ğ‘‘ğ‘ = 1.0, and ğœ†ğ‘Ÿğ‘’ğ‘”ğ· = 5ğ‘’ âˆ’ 3.

# why:
# '''
# pretrained_modelpath: '/ps/scratch/yfeng/Data/Projects-data/DECA-training/training/DECA_SIGGRAPH/pretrain/model.tar'
output_dir: "/media/wang/SSD_2/demo/AlbedoGAN_TR/detail/0528_resnet50_b3K3_68_1080"
#tensorboard --logdir /media/wang/SSD_2/demo/DECA_TR/pretrain/0307_convnextV2_8_235_1080/logs
pretrained_modelpath: '/media/wang/SSD_2/demo/DECA/data/deca_model.tar'

#æ•°æ®é›†åœ°å€
facescape_dir: "/media/wang/SSD_2/Datasets/FaceScape/fmview_train_new"
small_facescape_dir: "/media/wang/SSD_2/Datasets/test_arcface"
vggface2_dir: "/media/wang/SSD_2/Datasets/vggface2_new"
lymh_dir: "/media/wang/SSD_2/Datasets/LYMH"

aflw2000_dir: "/media/wang/SSD_2/Datasets/AFLW2000/image/2"

use_mica: True
train_other_params: False

dataset:
  training_data: ['small_facescape','facescape']
  eval_data: [ 'aflw2000' ]
  batch_size: 3
  num_workers: 4
  K: 2 #æ³¨æ„ä¿®æ”¹<æ•°æ®é›†æ–‡ä»¶å¤¹>
  isSingle: False

train:
  train_detail: True
  resume: True
  lr: 2e-4 #5e-4
  max_epochs: 10
  max_steps: 1000000
  log_steps: 10
  vis_steps: 500
  checkpoint_steps: 1000
  val_steps: 500
  eval_steps: 1000


# python main_train_deca_release.py --cfg configs/release_version/deca_coarse.yml